# ğŸš€ Kubernetes ChatOps Assistant

This repository contains a **Kubernetes ChatOps Assistant** that leverages AI models to interpret natural language queries, generate `kubectl` commands, and execute them securely. The assistant provides explanations for the commands and troubleshooting guidance.

![ChatOps](https://github.com/user-attachments/assets/23901c74-08bd-45b9-93ef-3002807d6315)

## ğŸ“Œ Features
- ğŸ§  **AI-Powered Command Generation**: Converts natural language queries into `kubectl` commands.
- ğŸ” **Command Execution**: Executes safe Kubernetes commands (`get`, `describe`, `logs`) and returns results.
- ğŸ›¡ **Security**: Prevents destructive commands like `delete`, `apply`, or `edit`.
- ğŸ”„ **Session Management**: Tracks conversation history and adapts to system prompt changes.
- ğŸ“Š **Cluster Insights**: Provides cluster health and status information.
- ğŸ›  **Multi-Model AI Support**: Works with OpenAI, Azure OpenAI, Gemini, Claude, and DeepSeek.

## ğŸ“‚ Project Structure
```
ğŸ“‚ ChatOPS
â”‚â”€â”€ ğŸ“‚ static/             # Static assets (CSS, JS, etc.)
â”‚â”€â”€ ğŸ“‚ templates/          # HTML templates for the Flask app
â”‚â”€â”€ ğŸ“‚ kubeconfig/         # Kubernetes config file
â”‚â”€â”€ ğŸ“‚ logs/               # Application logs
â”‚â”€â”€ ğŸ“‚ db/                 # SQLite database for conversation history
â”‚â”€â”€ ğŸ“„ app.py              # Main Flask application
â”‚â”€â”€ ğŸ“„ .env                # Environment variables (model provider & keys)
â”‚â”€â”€ ğŸ“„ requirements.txt    # Python dependencies
â”œâ”€â”€ ğŸ“„ Dockerfile          # Docker container definition
â”œâ”€â”€ ğŸ“„ .dockerignore       # Docker ignore rules
â”‚â”€â”€ ğŸ“„ README.md           # Documentation (You're here!)
â„¹ï¸ The dataset/ folder is only for reference â€” it's the data used during model fine-tuning and not required for runtime.
```

## ğŸ”§ Installation & Setup

### 1ï¸âƒ£ Install Required Packages
```sh
apt install python3.12-venv
python3 -m venv .venv
source .venv/bin/activate
python3 -m pip install -r requirements.txt
python3 -m pip install --upgrade -q google-api-python-client google-auth-httplib2 google-auth-oauthlib
python3 app.py
```

### 2ï¸âƒ£ Configure Environment Variables
Create a `.env` file in the project root and set the following variables:
```
# Select the model provider to use
MODEL_PROVIDER = "azure"  # Options: "openai", "gemini", "deepseek", "claude", "azure_openai"

# API Keys
OPENAI_API_KEY="your-openai-api-key"
GEMINI_API_KEY="your-gemini-api-key"
DEEPSEEK_API_KEY="your-deepseek-api-key"
CLAUDE_API_KEY="your-claude-api-key"
AZURE_OPENAI_API_KEY="your-azureopenai-api-key"

# Model Names
GEMINI_MODEL="tunedModels/k8schatbox-fs06ghlt6rvc" # https://ai.google.dev/gemini-api/docs/oauth
OPENAI_MODEL=gpt-4
DEEPSEEK_MODEL=deepseek-llm
CLAUDE_MODEL=claude-3-sonnet-2024-02-19

# Azure OpenAI Endpoint
AZURE_OPENAI_MODEL="<model_name>"
AZURE_OPENAI_DEPLOYMENT_NAME="k8s_chatbox"
AZURE_OPENAI_API_VERSION="<version>"
AZURE_OPENAI_ENDPOINT="<URL>"

# Logging Level (DEBUG/INFO/WARNING/ERROR)
LOG_LEVEL=DEBUG

# Kubeconfig Path
KUBECONFIG_PATH=kubeconfig/config
```

The application will start on `http://0.0.0.0:5000`.

## ğŸ” How It Works
1. **Natural Language Query**: Users input queries like "Show me all pods in the default namespace."
2. **AI Processing**: The assistant converts the query into a `kubectl` command.
3. **Command Execution**: The command is executed, and the results are returned to the user.
4. **Explanation**: The assistant provides an explanation of the command and its output.

âš ï¸ Note:

If you plan to use or continue fine-tuning with Google Gemini, you'll need to implement OAuth 2.0 authentication as outlined in Google's documentation:

ğŸ”— [Gemini OAuth Setup Guide](https://ai.google.dev/gemini-api/docs/oauth)

ğŸ³ Docker Setup
```
docker build -t kubernetes-chatbot .
docker run -p 5000:5000 --env-file .env kubernetes-chatbot
```

## ğŸ¤– Supported AI Models

The project supports multiple AI models for Terraform code generation and error fixing. You can configure the model provider in your `.env` file.

| Provider      | API Key Required | Model Name           | API Endpoint Required |
|--------------|----------------|----------------------|----------------------|
| **OpenAI**       | âœ… Yes         | `Fine-Tuning`   | âŒ No  |
| **Gemini**       | âœ… Yes         | `Fine-Tuning`   | âŒ No  |
| **DeepSeek**     | âœ… Yes         | `Fine-Tuning`   | âŒ No  |
| **Claude**       | âœ… Yes         | `Fine-Tuning`   | âŒ No  |
| **Azure OpenAI** | âœ… Yes         | `Fine-Tuning`   | âœ… Yes |

ğŸ¤ Contributing

Contributions and suggestions are welcome! Feel free to fork the repo and submit a pull request.
