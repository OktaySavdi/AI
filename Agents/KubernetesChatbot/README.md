ğŸ¤– Kubernetes Chatbot â€“ LLM-Powered Knowledge Assistant
This project is an AI-powered chatbot application designed to answer Kubernetes-related questions using a fine-tuned large language model (LLM). It enables users to interact in natural language and receive context-aware responses based on Kubernetes architecture, configuration, and operations.

ğŸ§  The underlying model has been fine-tuned on a custom Kubernetes dataset, improving its accuracy and relevance for real-world use cases.

https://github.com/user-attachments/assets/94e269d6-6a64-461f-88f7-491ba1c85de6

![2025-03-31 14_02_00-Kubernetes Agent Chatbot - Work - Microsoftâ€‹ Edge](https://github.com/user-attachments/assets/d43ee038-8f60-482e-8b28-3560eb0dfe4c)

![2025-03-28 14_49_11-k8s_chatbox _ Google AI Studio](https://github.com/user-attachments/assets/93fb49e3-e4e1-4943-b414-3cb53eaebdba)


ğŸš€ Features
```
âœ… Fine-tuned LLM focused on Kubernetes knowledge
âœ… Natural language chatbot interface
âœ… Contextual understanding of K8s architecture & troubleshooting
âœ… Flask-based web UI for fast interaction
âœ… Simple Docker deployment
```
ğŸ“ Project Structure
```
KubernetesChatbot/
â”œâ”€â”€ app.py               # Main Flask application
â”œâ”€â”€ dataset/             # Sample dataset used for fine-tuning (optional)
â”œâ”€â”€ db/                  # Stores conversation history or metadata
â”œâ”€â”€ logs/                # Logging output from app activity
â”œâ”€â”€ static/              # CSS, JavaScript, and static assets
â”œâ”€â”€ templates/           # HTML templates for frontend
â”œâ”€â”€ .env                 # Environment variables (model provider & keys)
â”œâ”€â”€ .dockerignore        # Docker ignore rules
â”œâ”€â”€ Dockerfile           # Docker container definition
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ README.md            # Project documentation
â„¹ï¸ The dataset/ folder is only for reference â€” it's the data used during model fine-tuning and not required for runtime.
```
ğŸ› ï¸ Technologies Used
```
Python
Flask
HuggingFace Transformers
Kubernetes-specific training data
```
ğŸ”§ Installation & Setup
```
1ï¸âƒ£ Install Required Packages
git clone https://github.com/your-username/KubernetesChatbot.git
cd KubernetesChatbot
apt install python3.12-venv
python3 -m venv .venv
source .venv/bin/activate
python3 -m pip install -r requirements.txt
python3 -m pip install --upgrade -q google-api-python-client google-auth-httplib2 google-auth-oauthlib
python3 app.py
```
### 2ï¸âƒ£ Configure Environment Variables
Create a `.env` file (or modify the existing one) and set API keys:
```
# Select the model provider to use
MODEL_PROVIDER = "azure"  # Options: "openai", "gemini", "deepseek", "claude", "azure_openai"

# API Keys
OPENAI_API_KEY="your-openai-api-key"
GEMINI_API_KEY="your-gemini-api-key"
DEEPSEEK_API_KEY="your-deepseek-api-key"
CLAUDE_API_KEY="your-claude-api-key"
AZURE_OPENAI_API_KEY="your-azureopenai-api-key"

# Model Names
GEMINI_MODEL="tunedModels/k8schatbox-fs06ghlt6rvc" # https://ai.google.dev/gemini-api/docs/oauth
OPENAI_MODEL=gpt-4
DEEPSEEK_MODEL=deepseek-llm
CLAUDE_MODEL=claude-3-sonnet-2024-02-19

# Azure OpenAI Endpoint
AZURE_OPENAI_MODEL="<model_name>"
AZURE_OPENAI_DEPLOYMENT_NAME="k8s_chatbox"
AZURE_OPENAI_API_VERSION="<version>"
AZURE_OPENAI_ENDPOINT="<URL>"
```
âš ï¸ Note:

If you plan to use or continue fine-tuning with Google Gemini, you'll need to implement OAuth 2.0 authentication as outlined in Google's documentation:

ğŸ”— [Gemini OAuth Setup Guide](https://ai.google.dev/gemini-api/docs/oauth)

ğŸ³ Docker Setup
```
docker build -t kubernetes-chatbot .
docker run -p 5000:5000 --env-file .env kubernetes-chatbot
```
ğŸ’¬ Sample Questions
```
"How do I configure a HorizontalPodAutoscaler in Kubernetes?"
"What's the difference between a ConfigMap and a Secret?"
"How can I debug a CrashLoopBackOff issue in my pod?"
```
ğŸ¯ Use Cases
```
Kubernetes Q&A assistant for developers and platform teams
Onboarding and internal knowledge sharing
Faster troubleshooting and reduced documentation search
Foundation for internal platform intelligence
```
## ğŸ¤– Supported AI Models

The project supports multiple AI models for Terraform code generation and error fixing. You can configure the model provider in your `.env` file.

| Provider      | API Key Required | Model Name           | API Endpoint Required |
|--------------|----------------|----------------------|----------------------|
| **OpenAI**       | âœ… Yes         | `Fine-Tuning`   | âŒ No  |
| **Gemini**       | âœ… Yes         | `Fine-Tuning`   | âŒ No  |
| **DeepSeek**     | âœ… Yes         | `Fine-Tuning`   | âŒ No  |
| **Claude**       | âœ… Yes         | `Fine-Tuning`   | âŒ No  |
| **Azure OpenAI** | âœ… Yes         | `Fine-Tuning`   | âœ… Yes |

ğŸ¤ Contributing

Contributions and suggestions are welcome! Feel free to fork the repo and submit a pull request.
